# üì¶ –≠—Ç–∞–ø 1: –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –º–æ–¥–µ–ª–∏ Word

> **–°—Ç–∞—Ç—É—Å**: ‚úÖ –ó–∞–≤–µ—Ä—à—ë–Ω  
> **–¢–∏–ø**: Backend  
> **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**: –ù–µ—Ç  
> **–°–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø**: 1.5 (WordRelation)

---

## üéØ –¶–µ–ª—å —ç—Ç–∞–ø–∞

–†–∞—Å—à–∏—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å `Word` –Ω–æ–≤—ã–º–∏ –ø–æ–ª—è–º–∏ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏:
- –≠—Ç–∏–º–æ–ª–æ–≥–∏–∏ (–∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è AI)
- –ü—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–¥–ª—è cloze –∫–∞—Ä—Ç–æ—á–µ–∫)
- –ü–æ–¥—Å–∫–∞–∑–æ–∫ (—Ç–µ–∫—Å—Ç + –∞—É–¥–∏–æ)
- –ó–∞–º–µ—Ç–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ (—Å—Ç–∏–∫–µ—Ä—ã)
- –°—Ç–∞—Ç—É—Å–∞ –æ–±—É—á–µ–Ω–∏—è

---

## üìã –ó–∞–¥–∞—á–∏

### 1. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ Word

- [x] **1.1** –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø–æ–ª—è –≤ –º–æ–¥–µ–ª—å
- [x] **1.2** –°–æ–∑–¥–∞—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é
- [x] **1.3** –û–±–Ω–æ–≤–∏—Ç—å —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ç–æ—Ä
- [x] **1.4** –û–±–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
- [x] **1.5** –ù–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç—ã

---

## üìÅ –§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è

| –§–∞–π–ª | –î–µ–π—Å—Ç–≤–∏–µ |
|------|----------|
| `backend/apps/words/models.py` | –ò–∑–º–µ–Ω–∏—Ç—å |
| `backend/apps/words/serializers.py` | –ò–∑–º–µ–Ω–∏—Ç—å |
| `backend/apps/words/views.py` | –ò–∑–º–µ–Ω–∏—Ç—å (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ) |
| `backend/apps/words/tests.py` | –ò–∑–º–µ–Ω–∏—Ç—å/–°–æ–∑–¥–∞—Ç—å |
| `frontend/src/types/index.ts` | –ò–∑–º–µ–Ω–∏—Ç—å |

---

## üíª –ö–æ–¥

### 1.1 –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ Word

**–§–∞–π–ª**: `backend/apps/words/models.py`

```python
from django.db import models
from django.conf import settings


class Word(models.Model):
    """–ú–æ–¥–µ–ª—å —Å–ª–æ–≤–∞ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è"""
    
    LANGUAGE_CHOICES = [
        ('ru', '–†—É—Å—Å–∫–∏–π'),
        ('en', 'English'),
        ('pt', '–ü–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–∏–π'),
        ('de', '–ù–µ–º–µ—Ü–∫–∏–π'),
        ('es', '–ò—Å–ø–∞–Ω—Å–∫–∏–π'),
        ('fr', '–§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π'),
        ('it', '–ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–π'),
    ]
    
    LEARNING_STATUS_CHOICES = [
        ('new', '–ù–æ–≤–æ–µ'),
        ('learning', '–í –∏–∑—É—á–µ–Ω–∏–∏'),
        ('reviewing', '–ù–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–∏'),
        ('mastered', '–û—Å–≤–æ–µ–Ω–æ'),
    ]
    
    PART_OF_SPEECH_CHOICES = [
        ('noun', '–°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ'),
        ('verb', '–ì–ª–∞–≥–æ–ª'),
        ('adjective', '–ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ'),
        ('adverb', '–ù–∞—Ä–µ—á–∏–µ'),
        ('pronoun', '–ú–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ'),
        ('preposition', '–ü—Ä–µ–¥–ª–æ–≥'),
        ('conjunction', '–°–æ—é–∑'),
        ('interjection', '–ú–µ–∂–¥–æ–º–µ—Ç–∏–µ'),
        ('article', '–ê—Ä—Ç–∏–∫–ª—å'),
        ('numeral', '–ß–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–µ'),
        ('particle', '–ß–∞—Å—Ç–∏—Ü–∞'),
        ('other', '–î—Ä—É–≥–æ–µ'),
    ]
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –°–£–©–ï–°–¢–í–£–Æ–©–ò–ï –ü–û–õ–Ø (–Ω–µ –º–µ–Ω—è—Ç—å!)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    user = models.ForeignKey(
        settings.AUTH_USER_MODEL,
        on_delete=models.CASCADE,
        related_name='words',
        verbose_name='–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å'
    )
    original_word = models.CharField(
        max_length=200,
        verbose_name='–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ'
    )
    translation = models.CharField(
        max_length=200,
        verbose_name='–ü–µ—Ä–µ–≤–æ–¥'
    )
    language = models.CharField(
        max_length=2,
        choices=LANGUAGE_CHOICES,
        verbose_name='–Ø–∑—ã–∫'
    )
    # DEPRECATED: card_type –ø–µ—Ä–µ–µ–¥–µ—Ç –≤ –º–æ–¥–µ–ª—å Card (–≠—Ç–∞–ø 3)
    # –ü–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    card_type = models.CharField(
        max_length=10,
        choices=[
            ('normal', '–û–±—ã—á–Ω–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞'),
            ('inverted', '–ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞'),
            ('empty', '–ü—É—Å—Ç–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞'),
        ],
        default='normal',
        verbose_name='–¢–∏–ø –∫–∞—Ä—Ç–æ—á–∫–∏ (deprecated)',
        help_text='DEPRECATED: –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞ Card'
    )
    audio_file = models.FileField(
        upload_to='audio/',
        null=True,
        blank=True,
        verbose_name='–ê—É–¥–∏–æ—Ñ–∞–π–ª'
    )
    image_file = models.ImageField(
        upload_to='images/',
        null=True,
        blank=True,
        verbose_name='–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ'
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        verbose_name='–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è'
    )
    updated_at = models.DateTimeField(
        auto_now=True,
        verbose_name='–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è'
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –ù–û–í–´–ï –ü–û–õ–Ø
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    # --- –ö–æ–Ω—Ç–µ–Ω—Ç (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è AI) ---
    etymology = models.TextField(
        blank=True,
        default='',
        verbose_name='–≠—Ç–∏–º–æ–ª–æ–≥–∏—è',
        help_text='–ü—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Å–ª–æ–≤–∞, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏'
    )
    
    sentences = models.JSONField(
        default=list,
        blank=True,
        verbose_name='–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π',
        help_text='–§–æ—Ä–º–∞—Ç: [{"text": "...", "source": "ai|user"}]'
    )
    
    # --- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç ---
    notes = models.TextField(
        blank=True,
        default='',
        verbose_name='–ó–∞–º–µ—Ç–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è'
    )
    
    # --- –ü–æ–¥—Å–∫–∞–∑–∫–∏ ---
    hint_text = models.TextField(
        blank=True,
        default='',
        verbose_name='–¢–µ–∫—Å—Ç–æ–≤–∞—è –ø–æ–¥—Å–∫–∞–∑–∫–∞',
        help_text='–û–ø–∏—Å–∞–Ω–∏–µ —Å–ª–æ–≤–∞ –±–µ–∑ –ø–µ—Ä–µ–≤–æ–¥–∞, –Ω–∞ –∏–∑—É—á–∞–µ–º–æ–º —è–∑—ã–∫–µ'
    )
    
    hint_audio = models.FileField(
        upload_to='hints/',
        null=True,
        blank=True,
        verbose_name='–ê—É–¥–∏–æ –ø–æ–¥—Å–∫–∞–∑–∫–∞'
    )
    
    # --- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ---
    part_of_speech = models.CharField(
        max_length=20,
        choices=PART_OF_SPEECH_CHOICES,
        blank=True,
        default='',
        verbose_name='–ß–∞—Å—Ç—å —Ä–µ—á–∏'
    )
    
    # --- –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è ---
    stickers = models.JSONField(
        default=list,
        blank=True,
        verbose_name='–°—Ç–∏–∫–µ—Ä—ã',
        help_text='–≠–º–æ—Ü–∏–∏/–Ω–∞–∫–ª–µ–π–∫–∏: ["‚ù§Ô∏è", "‚≠ê", "üî•"]'
    )
    
    # --- –°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è ---
    learning_status = models.CharField(
        max_length=20,
        choices=LEARNING_STATUS_CHOICES,
        default='new',
        verbose_name='–°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è'
    )
    
    class Meta:
        verbose_name = '–°–ª–æ–≤–æ'
        verbose_name_plural = '–°–ª–æ–≤–∞'
        ordering = ['-created_at']
        unique_together = [['user', 'original_word', 'language']]
        indexes = [
            models.Index(fields=['user', 'language']),
            models.Index(fields=['user', 'original_word']),
            models.Index(fields=['user', 'learning_status']),
        ]
    
    def __str__(self):
        return f"{self.original_word} ({self.language}) - {self.translation}"
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –ú–ï–¢–û–î–´
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def add_sentence(self, text: str, source: str = 'user') -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫ —Å–ª–æ–≤—É"""
        if not isinstance(self.sentences, list):
            self.sentences = []
        self.sentences.append({
            'text': text,
            'source': source  # 'ai' –∏–ª–∏ 'user'
        })
        self.save(update_fields=['sentences'])
    
    def add_sticker(self, emoji: str) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å—Ç–∏–∫–µ—Ä –∫ —Å–ª–æ–≤—É"""
        if not isinstance(self.stickers, list):
            self.stickers = []
        if emoji not in self.stickers:
            self.stickers.append(emoji)
            self.save(update_fields=['stickers'])
    
    def remove_sticker(self, emoji: str) -> None:
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∏–∫–µ—Ä —Å–æ —Å–ª–æ–≤–∞"""
        if isinstance(self.stickers, list) and emoji in self.stickers:
            self.stickers.remove(emoji)
            self.save(update_fields=['stickers'])
```

---

### 1.2 –°–æ–∑–¥–∞–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏

**–ö–æ–º–∞–Ω–¥–∞:**
```bash
cd backend
python manage.py makemigrations words --name add_training_fields
python manage.py migrate
```

**–û–∂–∏–¥–∞–µ–º–∞—è –º–∏–≥—Ä–∞—Ü–∏—è** (–ø—Ä–∏–º–µ—Ä–Ω–æ):
```python
# backend/apps/words/migrations/XXXX_add_training_fields.py

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('words', '0005_fix_all_card_types'),  # –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è
    ]

    operations = [
        migrations.AddField(
            model_name='word',
            name='etymology',
            field=models.TextField(blank=True, default='', verbose_name='–≠—Ç–∏–º–æ–ª–æ–≥–∏—è'),
        ),
        migrations.AddField(
            model_name='word',
            name='sentences',
            field=models.JSONField(blank=True, default=list, verbose_name='–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π'),
        ),
        migrations.AddField(
            model_name='word',
            name='notes',
            field=models.TextField(blank=True, default='', verbose_name='–ó–∞–º–µ—Ç–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è'),
        ),
        migrations.AddField(
            model_name='word',
            name='hint_text',
            field=models.TextField(blank=True, default='', verbose_name='–¢–µ–∫—Å—Ç–æ–≤–∞—è –ø–æ–¥—Å–∫–∞–∑–∫–∞'),
        ),
        migrations.AddField(
            model_name='word',
            name='hint_audio',
            field=models.FileField(blank=True, null=True, upload_to='hints/', verbose_name='–ê—É–¥–∏–æ –ø–æ–¥—Å–∫–∞–∑–∫–∞'),
        ),
        migrations.AddField(
            model_name='word',
            name='part_of_speech',
            field=models.CharField(blank=True, default='', max_length=20, verbose_name='–ß–∞—Å—Ç—å —Ä–µ—á–∏'),
        ),
        migrations.AddField(
            model_name='word',
            name='stickers',
            field=models.JSONField(blank=True, default=list, verbose_name='–°—Ç–∏–∫–µ—Ä—ã'),
        ),
        migrations.AddField(
            model_name='word',
            name='learning_status',
            field=models.CharField(
                choices=[
                    ('new', '–ù–æ–≤–æ–µ'),
                    ('learning', '–í –∏–∑—É—á–µ–Ω–∏–∏'),
                    ('reviewing', '–ù–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–∏'),
                    ('mastered', '–û—Å–≤–æ–µ–Ω–æ'),
                ],
                default='new',
                max_length=20,
                verbose_name='–°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è'
            ),
        ),
        migrations.AddIndex(
            model_name='word',
            index=models.Index(fields=['user', 'learning_status'], name='words_word_user_id_learning_idx'),
        ),
    ]
```

---

### 1.3 –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ç–æ—Ä–∞

**–§–∞–π–ª**: `backend/apps/words/serializers.py`

```python
from rest_framework import serializers
from .models import Word


class WordSerializer(serializers.ModelSerializer):
    """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–ª–æ–≤–∞ (–ø–æ–ª–Ω—ã–π)"""
    
    class Meta:
        model = Word
        fields = [
            'id',
            'original_word',
            'translation',
            'language',
            'card_type',  # deprecated, –Ω–æ –ø–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º
            'audio_file',
            'image_file',
            # –ù–æ–≤—ã–µ –ø–æ–ª—è
            'etymology',
            'sentences',
            'notes',
            'hint_text',
            'hint_audio',
            'part_of_speech',
            'stickers',
            'learning_status',
            # Timestamps
            'created_at',
            'updated_at',
        ]
        read_only_fields = ['id', 'created_at', 'updated_at']


class WordListSerializer(serializers.ModelSerializer):
    """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤ (–∫–æ–º–ø–∞–∫—Ç–Ω—ã–π)"""
    
    class Meta:
        model = Word
        fields = [
            'id',
            'original_word',
            'translation',
            'language',
            'audio_file',
            'image_file',
            'learning_status',
            'part_of_speech',
            'created_at',
        ]


class WordCreateSerializer(serializers.ModelSerializer):
    """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª–æ–≤–∞"""
    
    class Meta:
        model = Word
        fields = [
            'original_word',
            'translation',
            'language',
            'audio_file',
            'image_file',
            'notes',
            'part_of_speech',
        ]


class WordUpdateSerializer(serializers.ModelSerializer):
    """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞"""
    
    class Meta:
        model = Word
        fields = [
            'original_word',
            'translation',
            'audio_file',
            'image_file',
            'etymology',
            'sentences',
            'notes',
            'hint_text',
            'hint_audio',
            'part_of_speech',
            'stickers',
            'learning_status',
        ]
        # –í—Å–µ –ø–æ–ª—è –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã –ø—Ä–∏ PATCH
        extra_kwargs = {field: {'required': False} for field in fields}
```

---

### 1.4 –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ TypeScript —Ç–∏–ø–æ–≤

**–§–∞–π–ª**: `frontend/src/types/index.ts`

–î–æ–±–∞–≤–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å:

```typescript
// ========== WORD (–æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π) ==========

export type LearningStatus = 'new' | 'learning' | 'reviewing' | 'mastered';

export type PartOfSpeech = 
  | 'noun' 
  | 'verb' 
  | 'adjective' 
  | 'adverb' 
  | 'pronoun' 
  | 'preposition' 
  | 'conjunction' 
  | 'interjection' 
  | 'article' 
  | 'numeral' 
  | 'particle' 
  | 'other';

export interface WordSentence {
  text: string;
  source: 'ai' | 'user';
}

export interface Word {
  id: number;
  original_word: string;
  translation: string;
  language: string;
  card_type?: 'normal' | 'inverted' | 'empty'; // deprecated
  audio_file: string | null;
  image_file: string | null;
  
  // –ù–æ–≤—ã–µ –ø–æ–ª—è
  etymology: string;
  sentences: WordSentence[];
  notes: string;
  hint_text: string;
  hint_audio: string | null;
  part_of_speech: PartOfSpeech | '';
  stickers: string[];  // ["‚ù§Ô∏è", "‚≠ê"]
  learning_status: LearningStatus;
  
  created_at: string;
  updated_at: string;
}

// –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª–æ–≤–∞ (–±–µ–∑ id –∏ timestamps)
export interface WordCreate {
  original_word: string;
  translation: string;
  language: string;
  audio_file?: File | null;
  image_file?: File | null;
  notes?: string;
  part_of_speech?: PartOfSpeech;
}

// –î–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞ (–≤—Å–µ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
export interface WordUpdate {
  original_word?: string;
  translation?: string;
  audio_file?: File | null;
  image_file?: File | null;
  etymology?: string;
  sentences?: WordSentence[];
  notes?: string;
  hint_text?: string;
  hint_audio?: File | null;
  part_of_speech?: PartOfSpeech;
  stickers?: string[];
  learning_status?: LearningStatus;
}
```

---

## üß™ –¢–µ—Å—Ç—ã

**–§–∞–π–ª**: `backend/apps/words/tests.py`

```python
import pytest
from django.test import TestCase
from django.contrib.auth import get_user_model
from rest_framework.test import APITestCase
from rest_framework import status

from .models import Word

User = get_user_model()


class WordModelTests(TestCase):
    """–¢–µ—Å—Ç—ã –º–æ–¥–µ–ª–∏ Word"""
    
    def setUp(self):
        self.user = User.objects.create_user(
            username='testuser',
            email='test@example.com',
            password='testpass123'
        )
    
    def test_create_word_with_new_fields(self):
        """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª–æ–≤–∞ —Å –Ω–æ–≤—ã–º–∏ –ø–æ–ª—è–º–∏"""
        word = Word.objects.create(
            user=self.user,
            original_word='Hund',
            translation='—Å–æ–±–∞–∫–∞',
            language='de',
            etymology='–û—Ç –¥—Ä–µ–≤–Ω–µ–≤–µ—Ä—Ö–Ω–µ–Ω–µ–º–µ—Ü–∫–æ–≥–æ hunt',
            notes='–ú—É–∂—Å–∫–æ–π —Ä–æ–¥: der Hund',
            hint_text='Ein Tier mit vier Beinen',
            part_of_speech='noun',
            learning_status='new'
        )
        
        self.assertEqual(word.etymology, '–û—Ç –¥—Ä–µ–≤–Ω–µ–≤–µ—Ä—Ö–Ω–µ–Ω–µ–º–µ—Ü–∫–æ–≥–æ hunt')
        self.assertEqual(word.notes, '–ú—É–∂—Å–∫–æ–π —Ä–æ–¥: der Hund')
        self.assertEqual(word.hint_text, 'Ein Tier mit vier Beinen')
        self.assertEqual(word.part_of_speech, 'noun')
        self.assertEqual(word.learning_status, 'new')
        self.assertEqual(word.sentences, [])
        self.assertEqual(word.stickers, [])
    
    def test_add_sentence(self):
        """–¢–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        word = Word.objects.create(
            user=self.user,
            original_word='Hund',
            translation='—Å–æ–±–∞–∫–∞',
            language='de'
        )
        
        word.add_sentence('Der Hund l√§uft schnell.', source='ai')
        word.add_sentence('Mein Hund ist braun.', source='user')
        
        word.refresh_from_db()
        self.assertEqual(len(word.sentences), 2)
        self.assertEqual(word.sentences[0]['text'], 'Der Hund l√§uft schnell.')
        self.assertEqual(word.sentences[0]['source'], 'ai')
        self.assertEqual(word.sentences[1]['source'], 'user')
    
    def test_add_sticker(self):
        """–¢–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∏–∫–µ—Ä–∞"""
        word = Word.objects.create(
            user=self.user,
            original_word='Liebe',
            translation='–ª—é–±–æ–≤—å',
            language='de'
        )
        
        word.add_sticker('‚ù§Ô∏è')
        word.add_sticker('‚≠ê')
        word.add_sticker('‚ù§Ô∏è')  # –î—É–±–ª–∏–∫–∞—Ç –Ω–µ –¥–æ–ª–∂–µ–Ω –¥–æ–±–∞–≤–∏—Ç—å—Å—è
        
        word.refresh_from_db()
        self.assertEqual(word.stickers, ['‚ù§Ô∏è', '‚≠ê'])
    
    def test_remove_sticker(self):
        """–¢–µ—Å—Ç —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–∏–∫–µ—Ä–∞"""
        word = Word.objects.create(
            user=self.user,
            original_word='Test',
            translation='—Ç–µ—Å—Ç',
            language='de',
            stickers=['‚ù§Ô∏è', '‚≠ê', 'üî•']
        )
        
        word.remove_sticker('‚≠ê')
        
        word.refresh_from_db()
        self.assertEqual(word.stickers, ['‚ù§Ô∏è', 'üî•'])
    
    def test_learning_status_default(self):
        """–¢–µ—Å—Ç –¥–µ—Ñ–æ–ª—Ç–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
        word = Word.objects.create(
            user=self.user,
            original_word='Test',
            translation='—Ç–µ—Å—Ç',
            language='de'
        )
        
        self.assertEqual(word.learning_status, 'new')
    
    def test_learning_status_choices(self):
        """–¢–µ—Å—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        for status_code, _ in Word.LEARNING_STATUS_CHOICES:
            word = Word.objects.create(
                user=self.user,
                original_word=f'Test_{status_code}',
                translation='—Ç–µ—Å—Ç',
                language='de',
                learning_status=status_code
            )
            self.assertEqual(word.learning_status, status_code)


class WordAPITests(APITestCase):
    """–¢–µ—Å—Ç—ã API –¥–ª—è Word"""
    
    def setUp(self):
        self.user = User.objects.create_user(
            username='testuser',
            email='test@example.com',
            password='testpass123'
        )
        self.client.force_authenticate(user=self.user)
        
        self.word = Word.objects.create(
            user=self.user,
            original_word='Haus',
            translation='–¥–æ–º',
            language='de',
            learning_status='new'
        )
    
    def test_get_word_with_new_fields(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ª–æ–≤–∞ —Å –Ω–æ–≤—ã–º–∏ –ø–æ–ª—è–º–∏"""
        response = self.client.get(f'/api/words/{self.word.id}/')
        
        self.assertEqual(response.status_code, status.HTTP_200_OK)
        self.assertIn('etymology', response.data)
        self.assertIn('sentences', response.data)
        self.assertIn('notes', response.data)
        self.assertIn('hint_text', response.data)
        self.assertIn('part_of_speech', response.data)
        self.assertIn('stickers', response.data)
        self.assertIn('learning_status', response.data)
    
    def test_update_word_new_fields(self):
        """–¢–µ—Å—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π —Å–ª–æ–≤–∞"""
        data = {
            'etymology': '–û—Ç —Å—Ä–µ–¥–Ω–µ–≤–µ—Ä—Ö–Ω–µ–Ω–µ–º–µ—Ü–∫–æ–≥–æ h≈´s',
            'notes': 'Das Haus - —Å—Ä–µ–¥–Ω–∏–π —Ä–æ–¥',
            'hint_text': 'Ein Geb√§ude zum Wohnen',
            'part_of_speech': 'noun',
            'learning_status': 'learning'
        }
        
        response = self.client.patch(f'/api/words/{self.word.id}/', data)
        
        self.assertEqual(response.status_code, status.HTTP_200_OK)
        
        self.word.refresh_from_db()
        self.assertEqual(self.word.etymology, '–û—Ç —Å—Ä–µ–¥–Ω–µ–≤–µ—Ä—Ö–Ω–µ–Ω–µ–º–µ—Ü–∫–æ–≥–æ h≈´s')
        self.assertEqual(self.word.notes, 'Das Haus - —Å—Ä–µ–¥–Ω–∏–π —Ä–æ–¥')
        self.assertEqual(self.word.learning_status, 'learning')
    
    def test_update_stickers(self):
        """–¢–µ—Å—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∏–∫–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ API"""
        data = {
            'stickers': ['‚ù§Ô∏è', '‚≠ê']
        }
        
        response = self.client.patch(f'/api/words/{self.word.id}/', data)
        
        self.assertEqual(response.status_code, status.HTTP_200_OK)
        
        self.word.refresh_from_db()
        self.assertEqual(self.word.stickers, ['‚ù§Ô∏è', '‚≠ê'])
    
    def test_filter_by_learning_status(self):
        """–¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Å—Ç–∞—Ç—É—Å—É –æ–±—É—á–µ–Ω–∏—è"""
        Word.objects.create(
            user=self.user,
            original_word='Katze',
            translation='–∫–æ—à–∫–∞',
            language='de',
            learning_status='reviewing'
        )
        
        response = self.client.get('/api/words/', {'learning_status': 'new'})
        
        self.assertEqual(response.status_code, status.HTTP_200_OK)
        # –î–æ–ª–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–æ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º 'new'
        for word in response.data.get('results', []):
            self.assertEqual(word['learning_status'], 'new')
```

---

## ‚úÖ Definition of Done

–≠—Ç–∞–ø —Å—á–∏—Ç–∞–µ—Ç—Å—è –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–º, –∫–æ–≥–¥–∞:

- [x] –í—Å–µ –Ω–æ–≤—ã–µ –ø–æ–ª—è –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –º–æ–¥–µ–ª—å Word
- [x] –ú–∏–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞
- [x] –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã
- [x] API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ–≤—ã–µ –ø–æ–ª—è
- [x] TypeScript —Ç–∏–ø—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã
- [x] –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç (`pytest`)
- [x] –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –Ω–µ —Å–ª–æ–º–∞–Ω
- [x] –ö–æ–¥ –ø—Ä–æ—à—ë–ª review

---

## üîÑ –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

```bash
# 1. –û–±–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å (—Ä—É—á–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)

# 2. –°–æ–∑–¥–∞—Ç—å –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é
cd backend
python manage.py makemigrations words --name add_training_fields
python manage.py migrate

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç—ã
pytest apps/words/tests.py -v

# 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å API
python manage.py runserver
# GET http://localhost:8000/api/words/
# PATCH http://localhost:8000/api/words/1/

# 5. –û–±–Ω–æ–≤–∏—Ç—å TypeScript —Ç–∏–ø—ã (—Ä—É—á–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
```

---

## üìù –ó–∞–º–µ—Ç–∫–∏

- –ü–æ–ª–µ `card_type` –ø–æ–º–µ—á–µ–Ω–æ –∫–∞–∫ deprecated, –Ω–æ –ù–ï —É–¥–∞–ª—è–µ–º ‚Äî –Ω—É–∂–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –¥–æ –≠—Ç–∞–ø–∞ 3
- `sentences` —Ö—Ä–∞–Ω–∏—Ç JSON –º–∞—Å—Å–∏–≤ –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏
- `stickers` ‚Äî –ø—Ä–æ—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ emoji —Å—Ç—Ä–æ–∫
- –ò–Ω–¥–µ–∫—Å –ø–æ `learning_status` –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

---

> **–°–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø**: [STAGE_01.5_WORD_RELATION.md](./STAGE_01.5_WORD_RELATION.md)
